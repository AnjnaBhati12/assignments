{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shivam Gupta Bluepi NLP assigment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgpQO5PTJ2Xd",
        "colab_type": "text"
      },
      "source": [
        "# Problem Statement\n",
        "You are provided with a text corpora of a Digital media news channel in two different languages, namely english and hindi. You are given the task of finding out the most relevant keywords from the text that would best represent the story. These keyword would then be used as tags of the stories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2f1MGrbJ1JA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# some common libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9GqS6vdKE19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shiv = pd.read_csv('/content/drive/My Drive/Bluepi/article.csv', header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMjZszOAKN1M",
        "colab_type": "text"
      },
      "source": [
        "### So, as the file was been read by system it took first rows as column name and to avoid that i used header=None in read statement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpPIBv2fKFtN",
        "colab_type": "code",
        "outputId": "c8beeee1-43ae-4737-c6b4-af417b5579ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "shiv.head()\n"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>676946</td>\n",
              "      <td>english</td>\n",
              "      <td>Fadnavis, Piyush Goyal perform 'bhoomi pujan' ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>standard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>676943</td>\n",
              "      <td>english</td>\n",
              "      <td>Trump freezes $200 mn in Syrian recovery funds...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>standard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>676946</td>\n",
              "      <td>english</td>\n",
              "      <td>Fadnavis, Piyush Goyal perform 'bhoomi pujan' ...</td>\n",
              "      <td>&lt;p&gt;Latur (Maharashtra) [India], Apr. 1 (ANI): ...</td>\n",
              "      <td>standard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>676941</td>\n",
              "      <td>english</td>\n",
              "      <td>Bhagalpur violence: Arijit Shashwat surrenders</td>\n",
              "      <td>&lt;p&gt;Patna (Bihar) [India], Apr. 1 (ANI): Union ...</td>\n",
              "      <td>standard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>676941</td>\n",
              "      <td>english</td>\n",
              "      <td>Bhagalpur violence: Arijit Shashwat surrenders</td>\n",
              "      <td>NaN</td>\n",
              "      <td>standard</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0        1  ...                                                  3         4\n",
              "0  676946  english  ...                                                NaN  standard\n",
              "1  676943  english  ...                                                NaN  standard\n",
              "2  676946  english  ...  <p>Latur (Maharashtra) [India], Apr. 1 (ANI): ...  standard\n",
              "3  676941  english  ...  <p>Patna (Bihar) [India], Apr. 1 (ANI): Union ...  standard\n",
              "4  676941  english  ...                                                NaN  standard\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuHzHeuDKFr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# renaming columns for better understanding\n",
        "shiv = shiv.rename(columns = {0: \"articleid\", 1: \"language\", 2: \"content\", 3: \"title\", 4: \"type\"})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPYRAN2PKcSD",
        "colab_type": "code",
        "outputId": "25ba360d-f340-4817-c22a-01f32b616498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "shiv.head()"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>articleid</th>\n",
              "      <th>language</th>\n",
              "      <th>content</th>\n",
              "      <th>title</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>676946</td>\n",
              "      <td>english</td>\n",
              "      <td>Fadnavis, Piyush Goyal perform 'bhoomi pujan' ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>standard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>676943</td>\n",
              "      <td>english</td>\n",
              "      <td>Trump freezes $200 mn in Syrian recovery funds...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>standard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>676946</td>\n",
              "      <td>english</td>\n",
              "      <td>Fadnavis, Piyush Goyal perform 'bhoomi pujan' ...</td>\n",
              "      <td>&lt;p&gt;Latur (Maharashtra) [India], Apr. 1 (ANI): ...</td>\n",
              "      <td>standard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>676941</td>\n",
              "      <td>english</td>\n",
              "      <td>Bhagalpur violence: Arijit Shashwat surrenders</td>\n",
              "      <td>&lt;p&gt;Patna (Bihar) [India], Apr. 1 (ANI): Union ...</td>\n",
              "      <td>standard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>676941</td>\n",
              "      <td>english</td>\n",
              "      <td>Bhagalpur violence: Arijit Shashwat surrenders</td>\n",
              "      <td>NaN</td>\n",
              "      <td>standard</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  articleid  ...      type\n",
              "0    676946  ...  standard\n",
              "1    676943  ...  standard\n",
              "2    676946  ...  standard\n",
              "3    676941  ...  standard\n",
              "4    676941  ...  standard\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz4t4Nn9NHax",
        "colab_type": "code",
        "outputId": "d998a5e7-fc56-415b-f058-843c728c244f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Punkt Sentence Tokenizer divides a text into a list of sentences, by using an unsupervised algorithm\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG-whj3xNQVx",
        "colab_type": "code",
        "outputId": "1c5426d3-3d2c-4099-a90e-1cff7af5c3fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "# converting type of column to str so that word_tokenizer can act upon it\n",
        "shiv['content'].astype(str)"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Fadnavis, Piyush Goyal perform 'bhoomi pujan' ...\n",
              "1       Trump freezes $200 mn in Syrian recovery funds...\n",
              "2       Fadnavis, Piyush Goyal perform 'bhoomi pujan' ...\n",
              "3          Bhagalpur violence: Arijit Shashwat surrenders\n",
              "4          Bhagalpur violence: Arijit Shashwat surrenders\n",
              "                              ...                        \n",
              "5644    बैंक कर्मी के शर्मनाक बोल, कहा- कठुआ गैंगरेप प...\n",
              "5645    ऐसा हमला कोई इंसान नहीं बल्कि कोई दानव ही कर स...\n",
              "5646    मथुरा में अवैध रूप से रह रहे 24 बांग्लादेशी सम...\n",
              "5647    पुष्कर में वीकेंड एंजॉय करने पहुंचीं किश्वर सह...\n",
              "5648    बैंक कर्मी के शर्मनाक बोल, कहा- कठुआ गैंगरेप प...\n",
              "Name: content, Length: 5649, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXu0stehKefE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenizing the column\n",
        "from nltk.tokenize import word_tokenize\n",
        "# con_token = word_tokenize(shiv['content'])\n",
        "# con_token\n",
        "shiv['tokenized_sents'] = shiv.apply(lambda row: word_tokenize(row['content']), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8Oi2NWYLPlw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting the word count of tokenized column\n",
        "shiv['word_count'] = shiv.apply(lambda row: len(row['tokenized_sents']), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkDuUhw8N3B-",
        "colab_type": "code",
        "outputId": "50fa7765-c479-415b-a496-6d211afc86cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "shiv.head()"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>articleid</th>\n",
              "      <th>language</th>\n",
              "      <th>content</th>\n",
              "      <th>title</th>\n",
              "      <th>type</th>\n",
              "      <th>tokenized_sents</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>676946</td>\n",
              "      <td>english</td>\n",
              "      <td>Fadnavis, Piyush Goyal perform 'bhoomi pujan' ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>standard</td>\n",
              "      <td>[Fadnavis, ,, Piyush, Goyal, perform, 'bhoomi,...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>676943</td>\n",
              "      <td>english</td>\n",
              "      <td>Trump freezes $200 mn in Syrian recovery funds...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>standard</td>\n",
              "      <td>[Trump, freezes, $, 200, mn, in, Syrian, recov...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>676946</td>\n",
              "      <td>english</td>\n",
              "      <td>Fadnavis, Piyush Goyal perform 'bhoomi pujan' ...</td>\n",
              "      <td>&lt;p&gt;Latur (Maharashtra) [India], Apr. 1 (ANI): ...</td>\n",
              "      <td>standard</td>\n",
              "      <td>[Fadnavis, ,, Piyush, Goyal, perform, 'bhoomi,...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>676941</td>\n",
              "      <td>english</td>\n",
              "      <td>Bhagalpur violence: Arijit Shashwat surrenders</td>\n",
              "      <td>&lt;p&gt;Patna (Bihar) [India], Apr. 1 (ANI): Union ...</td>\n",
              "      <td>standard</td>\n",
              "      <td>[Bhagalpur, violence, :, Arijit, Shashwat, sur...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>676941</td>\n",
              "      <td>english</td>\n",
              "      <td>Bhagalpur violence: Arijit Shashwat surrenders</td>\n",
              "      <td>NaN</td>\n",
              "      <td>standard</td>\n",
              "      <td>[Bhagalpur, violence, :, Arijit, Shashwat, sur...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  articleid  ... word_count\n",
              "0    676946  ...         13\n",
              "1    676943  ...         12\n",
              "2    676946  ...         13\n",
              "3    676941  ...          6\n",
              "4    676941  ...          6\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O-Wz4ovOIG0",
        "colab_type": "code",
        "outputId": "1ebadde8-006f-46ec-fa40-d6a805f6f5dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "shiv[['tokenized_sents', 'word_count']].head()"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokenized_sents</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Fadnavis, ,, Piyush, Goyal, perform, 'bhoomi,...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Trump, freezes, $, 200, mn, in, Syrian, recov...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Fadnavis, ,, Piyush, Goyal, perform, 'bhoomi,...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Bhagalpur, violence, :, Arijit, Shashwat, sur...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Bhagalpur, violence, :, Arijit, Shashwat, sur...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     tokenized_sents  word_count\n",
              "0  [Fadnavis, ,, Piyush, Goyal, perform, 'bhoomi,...          13\n",
              "1  [Trump, freezes, $, 200, mn, in, Syrian, recov...          12\n",
              "2  [Fadnavis, ,, Piyush, Goyal, perform, 'bhoomi,...          13\n",
              "3  [Bhagalpur, violence, :, Arijit, Shashwat, sur...           6\n",
              "4  [Bhagalpur, violence, :, Arijit, Shashwat, sur...           6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZXComjjPxDG",
        "colab_type": "code",
        "outputId": "a53fb435-388d-4aad-ef20-fa99a460d5ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "#Identify common words\n",
        "comm = pd.Series(' '.join(shiv['content']).split()).value_counts()[:20]\n",
        "comm"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "के        1523\n",
              "में       1240\n",
              "की        1121\n",
              "ने         961\n",
              "in         835\n",
              "का         755\n",
              "to         752\n",
              "को         727\n",
              "से         635\n",
              "पर         633\n",
              "of         576\n",
              "for        323\n",
              "उन्नाव     308\n",
              "और         297\n",
              "Unnao      291\n",
              "है         290\n",
              "on         281\n",
              "CWG        260\n",
              "BJP        240\n",
              "2018:      239\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMRiMLKDQF6Y",
        "colab_type": "code",
        "outputId": "05833761-b0b4-4a20-cebd-57839c816349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Libraries for text preprocessing\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "nltk.download('wordnet') \n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJfq56NUQwvM",
        "colab_type": "code",
        "outputId": "1d00fc61-8e38-4dc4-a1cf-8818db859289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Stemming is a rudimentary rule-based process of stripping the suffixes (“ing”, “ly”, “es”, “s” etc) from a word for which i use PorterStemmer.\n",
        "# Lemmatization is an organized & step by step procedure of obtaining the root form of the word and for this we use WordNetLemmatizer.\n",
        "\n",
        "lem = WordNetLemmatizer()\n",
        "stem = PorterStemmer()\n",
        "word = \"perfectly\"\n",
        "print(\"stemming:\",stem.stem(word))\n",
        "print(\"lemmatization:\", lem.lemmatize(word, \"v\"))"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stemming: perfectli\n",
            "lemmatization: perfectly\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDxETUPcQwtn",
        "colab_type": "code",
        "outputId": "e5a9274f-f298-4eeb-9a6c-b23a9e56e8c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# creating a list of stop words\n",
        "stop_words = stopwords.words(\"english\")\n",
        "stop_words[:15]"
      ],
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSFm3p4hQwqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# By using regex expression removing punctuations and special characters\n",
        "data = []\n",
        "\n",
        "for i in range(0, 5649):\n",
        "    # Remove punctuations\n",
        "    txt = re.sub('[^a-zA-Z]', ' ', shiv['content'][i])\n",
        "    \n",
        "    # Convert to lowercase\n",
        "    txt = txt.lower()\n",
        "    \n",
        "    # remove special characters and digits\n",
        "    txt=re.sub(\"(\\d|\\W)+\",\" \",txt)\n",
        "\n",
        "    # removing punctuation mark and special characters\n",
        "    txt=re.sub('[-.?!,:;()|0-9]', ' ', txt)\n",
        "    \n",
        "    # Convert to list from string\n",
        "    txt = txt.split()\n",
        "    \n",
        "    # Lemmatisation\n",
        "    lem = WordNetLemmatizer()\n",
        "    \n",
        "    txt = [lem.lemmatize(word) for word in txt if not word in stop_words] \n",
        "    txt = \" \".join(txt)\n",
        "    data.append(txt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns9Ip5b_QwnO",
        "colab_type": "code",
        "outputId": "ddf7a32f-ff19-4e86-a09a-ec0783c534df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data[10]"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'kodandaram party get green signal'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZEk54wtA48z",
        "colab_type": "text"
      },
      "source": [
        "### CountVectorizer\n",
        "\n",
        "- It is a method of converting text data into vectors as model can process only numerical data.\n",
        "\n",
        "- In this we can only count the number of times a word appears in the document which results in biasing in favour of most frequent words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_XUr4q3AxhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import re\n",
        "cv=CountVectorizer(max_df=1.0,stop_words=stop_words, max_features=10000)\n",
        "x=cv.fit_transform(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSraVMjGBkQf",
        "colab_type": "code",
        "outputId": "66e056a9-7eaa-4d07-9c25-864272ca23db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "list(cv.vocabulary_.keys())[:10]"
      ],
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fadnavis',\n",
              " 'piyush',\n",
              " 'goyal',\n",
              " 'perform',\n",
              " 'bhoomi',\n",
              " 'pujan',\n",
              " 'latur',\n",
              " 'rail',\n",
              " 'coach',\n",
              " 'factory']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsYK02ynADDz",
        "colab_type": "text"
      },
      "source": [
        "### TfidfVectorizer \n",
        "\n",
        "- It is also a methods of converting text data into vectors as model can process only numerical data.\n",
        "- In TfidfVectorizer we consider overall document weightage of a word. It helps us in dealing with most frequent words. Using it we can penalize them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvQve39gACwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        " \n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(x)\n",
        " \n",
        "# fetch document for which keywords needs to be extracted\n",
        "doc=data[101]\n",
        " \n",
        "#generate tf-idf for the given document\n",
        "tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6M1lPOOuLdt",
        "colab_type": "code",
        "outputId": "a26237ea-5fa7-4187-d608-b263dd52382e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data[101]"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'england take charge day christchurch test'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJsXtakX2m1h",
        "colab_type": "code",
        "outputId": "b077976b-f59a-4ee0-cc3d-9cc3eb287655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "# to check whether tf_idf score row-wise\n",
        "\n",
        "feature_names = cv.get_feature_names()\n",
        " \n",
        "#get tfidf vector for first document\n",
        "first_document_vector=tf_idf_vector[0]\n",
        " \n",
        "#print the scores\n",
        "df = pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"])\n",
        "df.sort_values(by=[\"tfidf\"],ascending=False)\n",
        "\n",
        "# Notice that some words are missing from this list. This is possibly due to internal pre-processing of CountVectorizer \n",
        "# where it removes single characters."
      ],
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tfidf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>christchurch</th>\n",
              "      <td>0.495083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>england</th>\n",
              "      <td>0.495083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>0.400995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>charge</th>\n",
              "      <td>0.395854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>take</th>\n",
              "      <td>0.336943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footballer</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>force</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>forced</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>forget</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zuckerberg</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2521 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 tfidf\n",
              "christchurch  0.495083\n",
              "england       0.495083\n",
              "test          0.400995\n",
              "charge        0.395854\n",
              "take          0.336943\n",
              "...                ...\n",
              "footballer    0.000000\n",
              "force         0.000000\n",
              "forced        0.000000\n",
              "forget        0.000000\n",
              "zuckerberg    0.000000\n",
              "\n",
              "[2521 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQuaYCiSaOBx",
        "colab_type": "text"
      },
      "source": [
        "The scores above make sense. The more common the word across documents, the lower its score and the more unique a word is to our first document the higher the score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT-SpBqOdQC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function for sorting tf_idf in descending order\n",
        "from scipy.sparse import coo_matrix\n",
        "def sort_coo(coo_matrix):\n",
        "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
        "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
        " \n",
        "def top_vector(feature_names, sorted_items, topn=10):\n",
        "\n",
        "    #use only topn items from vector\n",
        "    sorted_items = sorted_items[:topn]\n",
        " \n",
        "    score_vals = []\n",
        "    feature_vals = []\n",
        "    \n",
        "    # word index and corresponding tf-idf score\n",
        "    for idx, score in sorted_items:\n",
        "        \n",
        "        #keep track of feature name and its corresponding score\n",
        "        score_vals.append(round(score, 3))\n",
        "        feature_vals.append(feature_names[idx])\n",
        " \n",
        "    #create a tuples of feature,score\n",
        "    results = zip(feature_vals,score_vals)\n",
        "    results= {}\n",
        "    for idx in range(len(feature_vals)):\n",
        "        results[feature_vals[idx]]=score_vals[idx]\n",
        "    \n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBl9TJAdZVPC",
        "colab_type": "code",
        "outputId": "b0be9353-bd5a-445b-b183-0636f77e2ad5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        }
      },
      "source": [
        "# just for the sake of showing that how below code works i am using a range of (0,5) else in actual scenario range would be (0, 5649)\n",
        "\n",
        "for i in range(0,6):\n",
        "    doc=data[i]\n",
        "    tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n",
        "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
        "    keywords=top_vector(feature_names,sorted_items,4)\n",
        "    \n",
        "    print(\"\\nRow no.:\",i,\"\\nContent:\",doc)\n",
        "    print(\"\\nKeywords:\")\n",
        "    for i in keywords:\n",
        "        print(i,keywords[i])"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Row no.: 0 \n",
            "Content: fadnavis piyush goyal perform bhoomi pujan latur rail coach factory\n",
            "\n",
            "Keywords:\n",
            "pujan 0.33\n",
            "piyush 0.33\n",
            "perform 0.33\n",
            "latur 0.33\n",
            "\n",
            "Row no.: 1 \n",
            "Content: trump freeze mn syrian recovery fund suggesting exit\n",
            "\n",
            "Keywords:\n",
            "suggesting 0.379\n",
            "recovery 0.379\n",
            "mn 0.379\n",
            "exit 0.379\n",
            "\n",
            "Row no.: 2 \n",
            "Content: fadnavis piyush goyal perform bhoomi pujan latur rail coach factory\n",
            "\n",
            "Keywords:\n",
            "pujan 0.33\n",
            "piyush 0.33\n",
            "perform 0.33\n",
            "latur 0.33\n",
            "\n",
            "Row no.: 3 \n",
            "Content: bhagalpur violence arijit shashwat surrender\n",
            "\n",
            "Keywords:\n",
            "surrender 0.461\n",
            "arijit 0.461\n",
            "shashwat 0.449\n",
            "bhagalpur 0.449\n",
            "\n",
            "Row no.: 4 \n",
            "Content: bhagalpur violence arijit shashwat surrender\n",
            "\n",
            "Keywords:\n",
            "surrender 0.461\n",
            "arijit 0.461\n",
            "shashwat 0.449\n",
            "bhagalpur 0.449\n",
            "\n",
            "Row no.: 5 \n",
            "Content: lawyer mp engaging judge impeachment barred practice court\n",
            "\n",
            "Keywords:\n",
            "practice 0.387\n",
            "judge 0.387\n",
            "impeachment 0.387\n",
            "engaging 0.387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5h2QgPGqrWt",
        "colab_type": "text"
      },
      "source": [
        "## In this way you can simply put in the row no of statement you want to find keywords and get the required results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "884oZg2qZVKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "30511e61-8044-4918-e5b1-db2641dc4d27"
      },
      "source": [
        "# if we want to find important keywords of statement at row number 2500\n",
        "\n",
        "doc=data[2500]\n",
        "tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n",
        "\n",
        "sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
        "keywords=top_vector(feature_names,sorted_items,3)\n",
        " \n",
        "print(\"\\ncontent:\", doc)\n",
        "print(\"\\nKeywords:\")\n",
        "for i in keywords:\n",
        "    print(i,keywords[i])"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "content: defexpo pm aim transform defence production procurement\n",
            "\n",
            "Keywords:\n",
            "transform 0.413\n",
            "production 0.413\n",
            "procurement 0.413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPVQeyGgQTeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}